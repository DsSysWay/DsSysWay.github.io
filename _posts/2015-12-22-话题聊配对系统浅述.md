---
layout: page
title: "话题聊配对系统方案设计"
categories:
- 系统 技术方案
tags:
- 系统设计
---



----

   去年年后接到一个独立系统，如下所示，需要根据某些话题为
两个不认识的人进行配对，配对上可以就该话题两个人交换意见聊天，
配对等待太久会结合用户属性出推荐话题。
大体样式如下图的两人牵线所示:
![话题](http://7xp7tl.com1.z0.glb.clouddn.com/subject.png)

![发起配对](http://7xp7tl.com1.z0.glb.clouddn.com/makepair.png)

![配对结束](http://7xp7tl.com1.z0.glb.clouddn.com/chat.png)


----


----


什么？你逗我？这太简单吧？这玩意也能叫一个系统？
我后台开个进程，每个话题开一个队列。看下队列有人就匹配上，没人就入队列
等着别人来跟他匹配。分分钟给你搞出来！
那么问题来了。

1.  用户在等待配对过程得通知后台吧，切出话题不想配对了也得通知后台把
用户从话题的等待配对队列里剔除。但是逻辑层是多台机子无状态的，如果退
出话题的请求先于心跳请求到达后台。那么用户还是会插入等待队列中被其他
用户匹配上。这个时序问题如何处理？
2. 匹配上了如何通知被匹配的一方?常规的通知是通过push下发，如果被配对的
对象刚好断网或者下线了呢？弱网络下如何保证基本体验？

3.  系统估计1亿用户百万在线。每个话题分十万人，后台架构如何设计才能
支撑可能存在的扎堆请求配对的问题？

4.  配对上的规则需要自由订制，例如男同女同话题只允许同性进入，暧昧话题
优先配对异性伙伴。星座话题优先配对相匹配星座伙伴，方案如何设计才能方便产品和运营需要？
。。。。。。

上面的问题考虑过没？

----

####下面先来聊下大概的一个方案设计问题。


----
前面陌生人群组的架构已经描述了整体的架构概况。而匹配服务
刚好是落在重型逻辑svr这一层。

最简单的方式是重型逻辑svr这一层做一个cache。然后每个话题建立一个队列。
每次配对请求到达的时候从cache中取出队列信息进行匹配。为了能在重启之后
快速恢复原来缓存中的信息，使用共享内存来管理cache。但是这种处理会带来
单点的问题。一旦匹配服务svr 挂机了就无法正常提供匹配服务。而我们做服务
的原则之一是保证成功率99.99% 以上。

因此需要在重型逻辑svr这一层加一个proxy。搞双机备份。但是关于cache的备份
又会带来数据同步的问题，是增量数据的时时同步，还是定时的同步。同步失败了
怎么处理？需要在proxy增加判定策略来判断服务是否可用。这套问题解决好了还有
新的问题。一旦匹配服务扛不住压力要扩容怎么办？很显然这套方案不利于平行扩展。
怎么降低这套东西的运维成本？这些是上面第一套方案需要面对的问题。



既然上面的方案对运维，扩容，以及版本升级的处理不是很友好，处理成本
相对较高。那我们来看看有什么优化的点。


之所以会出现上述问题，是因为逻辑层有状态，那将逻辑层处理成无状态，
状态保存在数据层。这样子可以直接使用基于内存的成熟数据库组件。但这种处理
方式会带来数据一致性问题。（分布式情况下访问相同的话题队列）。这种情况
需要怎么处理？遇到这种问题需要从业务数据模型出发。


按照以往产品得到的数据模型统计。从时间上分布同一个话题大概峰值是每秒1000
次配对操作。而db内网一次数据往返时延是10ms。运算下来出现数据冲突的概率在1%左右，
如果增加二次重试是0.01%（这里的估算是有问题的！）。因此把状态保存到db层这种
处理方式完全可以满足业务的需要。



----


####重新再回到刚才聊到的话题


----

1. 配对时序问题。进入配对之后，每隔5s钟会有一次配对心跳到达。来确保用户还是
在当前页面等待配对。如下所示：如果A发起配对请求进入等待队列了，在心跳发出来
不久用户选择退出该话题配对了。客户端是采用请求入单队列的形式。请求从用户到
接入机还是有序的，但是请求从轻逻辑层开始就无法保证有序了。因此在处理配对请
求的时候，退出话题配对的请求到达，剔除等待用户。心跳请求稍后到达，又将本已经
退出话题的用户压入等待队列中。
最直观的体验是。我等了一会，没有等到配对对象，结果退出话题，一会客户端又显示配对上了。
具体情况如下所示：



针对这种情况可以采用以下方案来处理。
配对请求本身包含以下过程：
发起请求配对，定时发起心跳表示还在等待，退出话题配对。

针对以上过程可以生成一个标记clientkey。这个clientkey可以使用用户名+时间戳+随机数生成。
在上述这组过程的请求都打上同一个clientkey。一旦退出话题配对，则在后台标记该clientkey
下的存储标志位，表示用户已经退出该话题了。如果接收到相同clientKey的心跳，就直接丢弃。
下次用户重新进入该话题，使用新生成的clientkey即可

具体数据结构表示如下：
处理方式：

后台维持一个key为clientkey，value为一个标志位的存储。客户端携带一个clientkey。
首次心跳到达后台会存储clientkey的值为0标志请求已经进入队列。取消操作会存储
clientkey的值为1标志取消操作。
（1）用户每次心跳上来都会查看clientkey存储的值是否为1，为1则直接丢弃心跳请求。
（说明用户已经取消这次配对了）为0则更新心跳时间。
clientkey会依照用户的操作场景累积起来，采用数据库自动淘汰方式淘汰即可。可以设置为1D
上述过程就变为如下图所示效果


2. 匹配上了如何通知被匹配的一方？常规的通知是通过push下发，如果被配对的对象刚好断网
或者下线了呢？弱网络下如何保证基本体验？
    目前Android在线push成功率大概在95%左右，在客户端收到客户端的回应包之后才会
认定为是收到push了。但是移动网络下面条件复杂，用户可能会出入电梯，可能在高铁上，
可能在干扰环境或者是基站覆盖信号较弱的地区，随时可能掉线。单纯靠push无法解决通知
到对方的问题。另外两人配对的时候，成功了，已有的解决方案是同时给双方发push，
会存在时序问题。一方A收到push，另一方B没有收到，那么另外一方会持续发心跳，
此时另外一方不在等待队列了。如果不将B重入队列，就会存在B一直等在配对过程页
的问题，除非push到达才能解决。如果将B重入队列，就会存在B同另外的人匹配上的情况。
从体验上来说是不合理的。

针对这种情况可以采用消息推送+拉取的方式来处理。
配对成功后会在被匹配方clientkey下标记匹配对方等到用户下次重连之后在新
的心跳里可以直接获取到被匹配的对象。


处理方式：
因此后台增加了一个新逻辑。A和B配对上了，就从队列中剔除。同时将A，B的配对
信息存起来。扩充存到
clientkey：key：clientkey，value：bool
这个数据结构里即可，上述数据结构变为
clientkey：key：clientkey，value：bool，配对上的uid
每配对上一次，都要记两个clientkey的数据，clientkeyA和clientkeyB
每次用户的心跳信息上来后，都会预先查看自己的clientkey下是否已经有配对信息了。
如果有，则返回给用户配对信息。如果没有，则走正常逻辑。依靠push和拉取
两种方式保障push下的体验问题。



如下所示



被匹配上的B push虽然接收失败了，但是重新连上来之后带的还是断线之前用的clientkey。
发送的心跳到达后台查下clientkey下面已经有匹配信息了，本次匹配过程就正式结束了。


解决完上述的问题，原本简单的匹配过程变成了下述的流程 


心跳主体流程图如下：



####正常心跳处理流程：

用户首次进入话题和心跳都走同一个协议
1. 拉取用户个人资料
2. 拉取话题等待队列
3. 查看队列中是否有人在等待。根据用户条件做匹配。如果配对上则将匹配对象出队列，
通过push  svr 给双方发一个配对成功的push  请求。如果匹配不上则查看是否在队列中，
不在则将用户存入队列，在则更新心跳时间戳。匹配过程校验用户的心跳时间戳，
如果过时则将用户清出排队队列。


####退出话题流程：

1. 拉取话题的等待队列
2. 将用户从队列中剔除。
3. 设置clienkey 下的bool值。
4. 话题的等待人数减一


####快速推荐流程：


向用户推荐话题是在用户等待多次之后没有匹配上，在心跳返回包里给用户返回
可以快速匹配到人的话题。用户达到某个心跳阀值后后台会快速推荐流程。心跳计数放
在attachinfo里，根据终端透传回来的用户计数来触发快速推荐逻辑，快速推荐整体流程如下：
1. 拉取用户个人资料
2. 拉取所有的话题列表
3. 根据用户属性和话题属性筛选话题。
4. 后台会维持每个话题前一个小时和当前小时的配对成功计数。作为话题配对速率。
根据配对速率和当前队列的等待人数做加权排序，取前两个。如果匹配不上则返回空包。
给用户推荐的话题会缓存到终端上，同时会在心跳协议的attchinfo里带上标志数据，
下次心跳来了就不再走推荐逻辑了。心跳协议里有attach_info 字段，通过客户端透传，
加入心跳计数，推荐的话题标志位。下次后台拿到后根据心跳计数和是否已经有推荐话题
标志来决定是否走快速推荐的话题流程




 

#####从这个独立系统里获得的收获是：

 

1. 移动网络下如何结合网络情况最大化的保证用户体验的完整性和逻辑的统一。
2. 需要在请求之间携带关联数据可以使用attch info 透传字段，类似于web的cookie 形式来记录一些关联数据
3. 业务技术选型可以根据访问的数据模型来确定。不要一开始就把思维给定死了。


----
